# -*- coding: utf-8 -*-
"""
╔══════════════════════════════════════════════════════════════════════════════╗
║  Phase 2 · Stage 3 — Interaction Term Discovery                            ║
║                                                                            ║
║  Pipeline position:                                                        ║
║    Stage 0 (Preselection) → Stage 1 (Univariate) → Stage 2 (SFFS)         ║
║      → [Stage 3: Interaction Terms]                                        ║
║                                                                            ║
║  Purpose:                                                                  ║
║    Discover synergistic feature interactions that improve predictive power  ║
║    beyond what the SFFS base features achieve alone. For example,           ║
║    LOGRET_5 * CMF_20 captures "volume-confirmed momentum" — a signal       ║
║    that neither feature encodes individually.                               ║
║                                                                            ║
║  Method:                                                                   ║
║    1. Load SFFS final subset (5 features) from sffs_report.json.           ║
║    2. Regenerate those 5 features from raw OHLCV (one-time TA cost).       ║
║    3. Create C(5,2) = 10 interaction columns (element-wise product).       ║
║    4. Run Forward Selection over the 10 interaction candidates:            ║
║       - Start with the 5 SFFS base features (frozen — never removed).      ║
║       - Greedily add the interaction that maximises Mean IC.               ║
║       - Stop when improvement < threshold OR max_interactions reached.     ║
║    5. Output the final feature set (base + selected interactions).         ║
║                                                                            ║
║  Key constraint: Base features are FROZEN. We only ADD interactions.       ║
║  This prevents the interaction search from destabilising the SFFS core.    ║
║                                                                            ║
║  Inputs  (from disk — fully decoupled):                                    ║
║    • artifacts/phase_2_features/sffs_report.json            (Stage 2)      ║
║    • artifacts/phase_1_data/merged_data.parquet              (Phase 1)     ║
║                                                                            ║
║  Outputs:                                                                  ║
║    • artifacts/phase_2_features/interaction_report.json                     ║
║    • artifacts/phase_2_features/manifest.json  (via Auditor)               ║
║                                                                            ║
║  Quality Gates:                                                            ║
║    ✓ Decoupled — reads only disk artifacts from prior stages               ║
║    ✓ Deterministic — Ridge has no random state; alphabetical tie-breaking  ║
║    ✓ Atomic — writes to .tmp then renames                                  ║
║    ✓ Efficient — TA regenerated ONCE; interactions are O(N) column ops;    ║
║      forward selection loop uses column slicing only                       ║
║    ✓ Traceable — full iteration log with scores at every step              ║
║    ✓ Temporal — TimeSeriesSplit preserves chronological order               ║
║    ✓ Conservative — max 3 interactions to guard against overfitting        ║
║                                                                            ║
║  TA Generation Note:                                                       ║
║    Sequential per-ticker (pandas_ta daemon constraint — see Stage 0).      ║
║    Only indicator specs producing the 5 SFFS columns are generated.        ║
║                                                                            ║
║  Version: 1.0.0                                                            ║
╚══════════════════════════════════════════════════════════════════════════════╝
"""

# ─── Imports ────────────────────────────────────────────────────────────────
from __future__ import annotations

import json
import sys
import warnings
from itertools import combinations
from pathlib import Path
from time import perf_counter
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

# ═══════════════════════════════════════════════════════════════
# SUPPRESS PANDAS_TA UPSTREAM FUTUREWARNING (BEFORE IMPORT)
# ═══════════════════════════════════════════════════════════════
# Pattern from 1_preselection_audit.py lines 37-42.
warnings.filterwarnings(
    "ignore",
    category=FutureWarning,
    message="Setting an item of incompatible dtype is deprecated",
    module="pandas_ta_classic",
)
warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)

from scipy.stats import spearmanr
from sklearn.linear_model import Ridge
from sklearn.model_selection import TimeSeriesSplit
from tqdm import tqdm

# ─── Project path bootstrap ────────────────────────────────────────────────
# Pattern from 1_preselection_audit.py lines 51-55.
CURRENT_FILE = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_FILE.parent.parent.parent

if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

import pandas_ta_classic as ta                         # noqa: E402
from core.audit import Auditor                         # noqa: E402
from core.io import write_json                         # noqa: E402
from phases.phase2.config import Phase2Config          # noqa: E402


# ─── Constants ──────────────────────────────────────────────────────────────
VERSION = "1.0.0"
STAGE_NAME = "3_interaction_terms"

PHASE1_ARTIFACT = PROJECT_ROOT / "artifacts" / "phase_1_data" / "merged_data.parquet"
PHASE2_ARTIFACT_DIR = PROJECT_ROOT / "artifacts" / "phase_2_features"
SFFS_REPORT_JSON = PHASE2_ARTIFACT_DIR / "sffs_report.json"
OUTPUT_JSON = PHASE2_ARTIFACT_DIR / "interaction_report.json"

REQUIRED_COLUMNS = {"ticker", "date", "open", "high", "low", "close", "volume"}

# Matched exactly to Stage 1/2 hyperparameters
RIDGE_ALPHA = 1.0
CV_FOLDS = 5
FORWARD_DAYS = 5

# Interaction-specific parameters
MAX_INTERACTIONS = 3               # Conservative cap to prevent overfitting
IC_IMPROVEMENT_THRESHOLD = 0.0005  # Same threshold as SFFS (Stage 2)


# ─── Indicator-to-column mapping ───────────────────────────────────────────
# Reused from Stage 1/2 — maps indicator "kind" to output column prefixes.
_KIND_TO_PREFIX: Dict[str, List[str]] = {
    "adx": ["ADX_", "DMP_", "DMN_"],
    "chop": ["CHOP_"],
    "aroon": ["AROOND_", "AROONU_", "AROONOSC_"],
    "supertrend": ["SUPERT_", "SUPERTd_", "SUPERTl_", "SUPERTs_"],
    "rsi": ["RSI_"],
    "roc": ["ROC_"],
    "macd": ["MACD_", "MACDh_", "MACDs_"],
    "mom": ["MOM_"],
    "willr": ["WILLR_"],
    "natr": ["NATR_"],
    "bbands": ["BBL_", "BBM_", "BBU_", "BBB_", "BBP_"],
    "atr": ["ATRr_"],
    "rvi": ["RVI_"],
    "cmf": ["CMF_"],
    "mfi": ["MFI_"],
    "obv": ["OBV"],
    "sma": ["SMA_"],
    "ema": ["EMA_"],
    "zscore": ["ZS_"],
    "skew": ["SKEW_"],
    "stdev": ["STDEV_"],
    "log_return": ["LOGRET_"],
    "percent_return": ["PCTRET_"],
}


# ─── CV Scoring Function ───────────────────────────────────────────────────
# Identical to Stage 2's _evaluate_subset. Factored out for reuse.
def _evaluate_subset(
    df: pd.DataFrame,
    feature_cols: List[str],
    target_col: str,
    tscv: TimeSeriesSplit,
    ridge: Ridge,
) -> Tuple[float, List[float]]:
    """Evaluate a feature subset via Ridge + TSCV + Spearman IC.

    Pure column slicing — no data transformation inside this function.

    Args:
        df: Pre-computed DataFrame with all features and target.
        feature_cols: Column names forming the candidate subset.
        target_col: Name of the target column.
        tscv: Pre-configured TimeSeriesSplit instance.
        ridge: Pre-configured Ridge instance.

    Returns:
        Tuple of (mean_ic, fold_ics_list).
        Returns (float('-inf'), []) if evaluation fails.
    """
    cols_needed = feature_cols + [target_col]
    subset = df[cols_needed].dropna()

    if len(subset) < CV_FOLDS * 2:
        return float("-inf"), []

    X = subset[feature_cols].values
    y = subset[target_col].values

    fold_ics: List[float] = []

    for train_idx, test_idx in tscv.split(X):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        ridge.fit(X_train, y_train)
        y_pred = ridge.predict(X_test)

        # Spearman IC — identical to Stage 1 (2_individual_evaluation.py)
        if np.std(y_pred) < 1e-15 or np.std(y_test) < 1e-15:
            ic = 0.0
        else:
            ic, _ = spearmanr(y_pred, y_test)
            if np.isnan(ic):
                ic = 0.0

        fold_ics.append(round(float(ic), 6))

    mean_ic = float(np.mean(fold_ics))
    return mean_ic, fold_ics


# ─── Main Class ─────────────────────────────────────────────────────────────
class InteractionTermSelector:
    """Discover interaction terms that improve the SFFS base model.

    Creates C(5,2) = 10 pairwise product features from the SFFS subset,
    then greedily adds the best interactions via forward selection with
    the base features frozen.
    """

    def __init__(self, config: Phase2Config) -> None:
        self.config = config

        # Auditor: exact contract from 1_preselection_audit.py lines 189-193
        self.auditor = Auditor(
            phase=config.phase,
            output_dir=str(config.get_resolved_output_dir()),
            version=config.version,
        )

        self._base_features: Optional[List[str]] = None
        self._base_score: Optional[float] = None
        self._interaction_names: Optional[List[str]] = None
        self._filtered_specs: Optional[List[Dict[str, Any]]] = None
        self._iteration_log: List[Dict[str, Any]] = []

    # ── 1. Load Stage 2 (SFFS) results ──────────────────────────────────────
    def load_sffs_results(self) -> Tuple[List[str], float]:
        """Load sffs_report.json and extract the final subset + baseline score.

        Returns:
            Tuple of (base_features_list, baseline_mean_ic).

        Raises:
            FileNotFoundError: If SFFS report is missing.
            AssertionError: If report is malformed.
        """
        print(f"\n{'='*72}")
        print(f"[Stage 3] Loading Stage 2 (SFFS) Results...")
        print(f"{'='*72}")

        if not SFFS_REPORT_JSON.exists():
            raise FileNotFoundError(
                f"[FATAL] Stage 2 output not found: {SFFS_REPORT_JSON}\n"
                f"       Run 3_sffs_selection.py before this script."
            )

        with open(SFFS_REPORT_JSON, "r", encoding="utf-8") as f:
            sffs_data = json.load(f)

        assert "final_subset" in sffs_data, (
            f"[SCHEMA VIOLATION] sffs_report.json missing 'final_subset' key.\n"
            f"  Found keys: {list(sffs_data.keys())}"
        )
        assert "final_score_mean_ic" in sffs_data, (
            f"[SCHEMA VIOLATION] sffs_report.json missing 'final_score_mean_ic'."
        )

        base_features = sffs_data["final_subset"]
        base_score = sffs_data["final_score_mean_ic"]

        assert isinstance(base_features, list) and len(base_features) > 0, (
            f"[SCHEMA VIOLATION] final_subset must be a non-empty list, "
            f"got: {base_features}"
        )

        print(f"  ✓ SFFS final subset ({len(base_features)} features):")
        for i, feat in enumerate(base_features, 1):
            print(f"    {i}. {feat}")
        print(f"  ✓ SFFS baseline Mean IC: {base_score:.6f}")

        self._base_features = base_features
        self._base_score = base_score
        return base_features, base_score

    # ── 2. Load Phase 1 data ────────────────────────────────────────────────
    def load_phase1_data(self) -> pd.DataFrame:
        """Load merged OHLCV and validate schema.

        Returns:
            pd.DataFrame: Raw OHLCV sorted by (ticker, date).
        """
        print(f"\n{'='*72}")
        print(f"[Stage 3] Loading Phase 1 Data...")
        print(f"{'='*72}")

        if not PHASE1_ARTIFACT.exists():
            raise FileNotFoundError(
                f"[FATAL] Phase 1 artifact not found: {PHASE1_ARTIFACT}\n"
                f"       Run Phase 1 before Phase 2."
            )

        t0 = perf_counter()
        df = pd.read_parquet(PHASE1_ARTIFACT)
        t_load = perf_counter() - t0

        df.columns = df.columns.str.lower().str.strip()
        print(f"  ✓ Loaded merged_data.parquet: {df.shape[0]:,} rows × "
              f"{df.shape[1]} cols  ({t_load:.2f}s)")

        missing = REQUIRED_COLUMNS - set(df.columns)
        assert len(missing) == 0, (
            f"[SCHEMA VIOLATION] Missing required columns: {missing}\n"
            f"  Present columns: {sorted(df.columns.tolist())}"
        )
        print(f"  ✓ Schema validated: {sorted(REQUIRED_COLUMNS)} all present")

        # Auditor lifecycle: start + record_input
        self.auditor.start()
        self.auditor.record_input(str(PHASE1_ARTIFACT), df)

        df = df.sort_values(["ticker", "date"]).reset_index(drop=True)
        return df

    # ── 3. Compute target ───────────────────────────────────────────────────
    @staticmethod
    def compute_target(df: pd.DataFrame) -> pd.Series:
        """Compute 5-day forward log return per ticker.

        Identical formula to Stage 1/2:  target_t = ln(close_{t+5} / close_t)

        Args:
            df: DataFrame sorted by (ticker, date) with 'close' column.

        Returns:
            pd.Series: Named 'target_log_return', index-aligned to df.
        """
        print(f"\n{'='*72}")
        print(f"[Stage 3] Computing Target: {FORWARD_DAYS}-day forward log return")
        print(f"{'='*72}")

        t0 = perf_counter()

        future_close = df.groupby("ticker")["close"].shift(-FORWARD_DAYS)
        target = np.log(future_close / df["close"])
        target.name = "target_log_return"

        n_valid = target.notna().sum()
        n_nan = target.isna().sum()
        t_elapsed = perf_counter() - t0
        print(f"  ✓ Target computed: {n_valid:,} valid / {n_nan:,} NaN  "
              f"({t_elapsed:.3f}s)")

        return target

    # ── 4. Regenerate base features ─────────────────────────────────────────
    def regenerate_features(
        self, df: pd.DataFrame, feature_list: List[str]
    ) -> pd.DataFrame:
        """Regenerate ONLY the SFFS base features from raw OHLCV.

        Uses _KIND_TO_PREFIX filtering. Sequential per-ticker
        (pandas_ta daemon constraint).

        Args:
            df: Raw OHLCV DataFrame.
            feature_list: SFFS base feature column names.

        Returns:
            pd.DataFrame: Input df augmented with regenerated columns.
        """
        print(f"\n{'='*72}")
        print(f"[Stage 3] Regenerating {len(feature_list)} Base Features "
              f"via pandas_ta_classic")
        print(f"{'='*72}")

        t0 = perf_counter()

        # ── Filter curated_indicators ───────────────────────────────────────
        all_specs = self.config.curated_indicators
        feature_set = set(feature_list)

        filtered_specs: List[Dict[str, Any]] = []
        for spec in all_specs:
            kind = spec.get("kind", "")
            prefixes = _KIND_TO_PREFIX.get(kind, [])
            produces_needed = any(
                any(feat.startswith(prefix) for feat in feature_set)
                for prefix in prefixes
            )
            if produces_needed:
                filtered_specs.append(spec)

        self._filtered_specs = filtered_specs
        print(f"  ℹ Filtered {len(all_specs)} curated specs → "
              f"{len(filtered_specs)} needed for {len(feature_list)} features")

        # ── Per-ticker TA generation (sequential) ───────────────────────────
        tickers = sorted(df["ticker"].unique())
        print(f"  ℹ Processing {len(tickers)} tickers with "
              f"{len(filtered_specs)} indicator specs (sequential)")

        ta_strategy = ta.Strategy(
            name="Phase2_Interaction_Base",
            ta=filtered_specs,
        )

        frames: List[pd.DataFrame] = []
        initial_cols = set(df.columns)
        generation_errors: List[str] = []

        for ticker_id in tqdm(
            tickers, desc="  [TA Generation]", unit="ticker"
        ):
            ticker_df = df[df["ticker"] == ticker_id].copy()

            try:
                ticker_df.ta.strategy(ta_strategy, verbose=False)
                frames.append(ticker_df)
            except Exception as e:
                generation_errors.append(str(ticker_id))
                if len(generation_errors) <= 5:
                    warnings.warn(
                        f"[Stage 3] pandas_ta failed for '{ticker_id}': {e}",
                        RuntimeWarning,
                        stacklevel=2,
                    )

        if not frames:
            raise RuntimeError(
                "All tickers failed indicator generation. "
                "Check pandas_ta_classic installation and input data quality."
            )

        if generation_errors:
            print(f"  ⚠ {len(generation_errors)} tickers failed: "
                  f"{generation_errors[:10]}")

        result_df = pd.concat(frames, axis=0, ignore_index=True)
        new_cols = set(result_df.columns) - initial_cols
        print(f"  ✓ TA strategy generated {len(new_cols)} new columns")

        # ── Verify base columns are present ─────────────────────────────────
        generated_cols = set(result_df.columns)
        matched = [c for c in feature_list if c in generated_cols]
        missing_cols = [c for c in feature_list if c not in generated_cols]

        # Case-insensitive fallback
        if missing_cols:
            col_map = {c.upper(): c for c in generated_cols}
            for m in missing_cols[:]:
                if m.upper() in col_map:
                    actual = col_map[m.upper()]
                    result_df.rename(columns={actual: m}, inplace=True)
                    matched.append(m)
                    missing_cols.remove(m)

        if missing_cols:
            raise RuntimeError(
                f"[FATAL] Cannot regenerate SFFS base features: {missing_cols}\n"
                f"  These are required for interaction term computation.\n"
                f"  Generated columns: {sorted(new_cols)}"
            )

        print(f"  ✓ Matched {len(matched)}/{len(feature_list)} base features")

        t_elapsed = perf_counter() - t0
        print(f"  ✓ Feature regeneration complete ({t_elapsed:.1f}s)")

        return result_df

    # ── 5. Create interaction columns ───────────────────────────────────────
    def create_interaction_columns(
        self, df: pd.DataFrame, base_features: List[str]
    ) -> Tuple[pd.DataFrame, List[str]]:
        """Create C(N,2) pairwise interaction columns via element-wise product.

        Interaction formula:  IX_{A_B} = A * B  (element-wise)

        This captures non-linear relationships that Ridge cannot model
        from the individual features alone. For example:
          - LOGRET_5 * CMF_20  → "volume-confirmed momentum"
          - ATRr_14 * ADX_14   → "volatility-adjusted trend strength"

        No normalisation is applied here — Ridge's L2 penalty handles
        scale differences. Feature scaling would add complexity and
        another hyperparameter with minimal benefit for Ridge.

        Args:
            df: DataFrame with base feature columns.
            base_features: Ordered list of SFFS base feature names.

        Returns:
            Tuple of (augmented_df, interaction_column_names).
        """
        print(f"\n{'='*72}")
        print(f"[Stage 3] Creating Interaction Terms")
        print(f"{'='*72}")

        t0 = perf_counter()

        # Generate all C(N,2) pairs in deterministic order
        # sorted() on each pair + sorted() on the list → fully deterministic
        pairs = list(combinations(sorted(base_features), 2))

        interaction_names: List[str] = []
        pair_descriptions: List[Dict[str, str]] = []

        for feat_a, feat_b in pairs:
            # Naming convention: IX_{featureA}_{featureB}
            # IX prefix distinguishes interaction columns from base features
            ix_name = f"IX_{feat_a}_x_{feat_b}"
            df[ix_name] = df[feat_a] * df[feat_b]
            interaction_names.append(ix_name)
            pair_descriptions.append({
                "name": ix_name,
                "feature_a": feat_a,
                "feature_b": feat_b,
            })

        t_elapsed = perf_counter() - t0

        print(f"  ✓ Created {len(interaction_names)} interaction columns "
              f"from C({len(base_features)},2) pairs  ({t_elapsed:.3f}s)")
        print(f"  Interactions:")
        for desc in pair_descriptions:
            print(f"    • {desc['name']}")

        self._interaction_names = interaction_names
        return df, interaction_names

    # ── 6. Forward selection over interactions ──────────────────────────────
    def run_interaction_selection(
        self, df: pd.DataFrame
    ) -> Dict[str, Any]:
        """Forward selection: greedily add interactions to the frozen base.

        The 5 SFFS base features are FROZEN — they are always included.
        We only search over which of the 10 interaction columns to ADD.

        Algorithm:
            1. Compute baseline score: Ridge(base_features) under TSCV.
            2. For each remaining interaction:
                - Evaluate Ridge(base_features + selected_interactions + [ix]).
                - Track best ix by Mean IC.
            3. If best ix improves score by ≥ threshold, add it.
            4. Stop when: no improvement, or max_interactions reached.

        Determinism:
            - Remaining interactions iterated in sorted order.
            - Ties broken alphabetically.

        Args:
            df: DataFrame with base features, interactions, and target.
                Must be sorted by (ticker, date).

        Returns:
            Dict with selected interactions, scores, and full iteration log.
        """
        print(f"\n{'='*72}")
        print(f"[Stage 3] Running Interaction Forward Selection")
        print(f"{'='*72}")
        print(f"  ℹ Base features (frozen): {self._base_features}")
        print(f"  ℹ Interaction candidates : {len(self._interaction_names)}")
        print(f"  ℹ Max interactions       : {MAX_INTERACTIONS}")
        print(f"  ℹ Model                  : Ridge(alpha={RIDGE_ALPHA})")
        print(f"  ℹ CV                     : TimeSeriesSplit(n_splits={CV_FOLDS})")
        print(f"  ℹ Stop threshold         : Δ IC < {IC_IMPROVEMENT_THRESHOLD}")

        t0 = perf_counter()

        target_col = "target_log_return"
        assert target_col in df.columns, (
            f"[FATAL] Target column '{target_col}' not in DataFrame."
        )

        # Sort for temporal integrity
        df = df.sort_values(["ticker", "date"]).reset_index(drop=True)

        tscv = TimeSeriesSplit(n_splits=CV_FOLDS)
        ridge = Ridge(alpha=RIDGE_ALPHA, fit_intercept=True)

        base_features = list(self._base_features)

        # ── Step 0: Verify baseline score ───────────────────────────────────
        # Re-evaluate base features to get a locally-computed baseline
        # (not trusting the Stage 2 JSON value — verify, not assume)
        baseline_ic, baseline_folds = _evaluate_subset(
            df, base_features, target_col, tscv, ridge
        )
        print(f"\n  ✓ Verified baseline Mean IC: {baseline_ic:.6f}")
        print(f"    (Stage 2 reported: {self._base_score:.6f})")

        if abs(baseline_ic - self._base_score) > 0.005:
            print(f"  ⚠ WARNING: Baseline mismatch > 0.005. "
                  f"Proceeding with locally computed value.")

        self._iteration_log.append({
            "iteration": 0,
            "step": "BASELINE",
            "features": list(base_features),
            "score_mean_ic": round(baseline_ic, 6),
            "fold_ics": baseline_folds,
            "sffs_reported_ic": self._base_score,
        })

        # ── Forward selection loop ──────────────────────────────────────────
        selected_interactions: List[str] = []
        remaining_interactions: List[str] = sorted(self._interaction_names)
        best_score: float = baseline_ic

        for iteration in range(1, MAX_INTERACTIONS + 1):
            if not remaining_interactions:
                self._iteration_log.append({
                    "iteration": iteration,
                    "step": "STOP",
                    "reason": "No remaining interaction candidates.",
                })
                print(f"\n  ▮ Iteration {iteration}: STOP — "
                      f"no remaining candidates")
                break

            # Try each remaining interaction
            candidates: List[Tuple[str, float, List[float]]] = []

            current_features = base_features + selected_interactions

            for ix_name in sorted(remaining_interactions):
                test_features = current_features + [ix_name]
                mean_ic, fold_ics = _evaluate_subset(
                    df, test_features, target_col, tscv, ridge
                )
                candidates.append((ix_name, mean_ic, fold_ics))

            # Sort: highest Mean IC first, alphabetical tie-breaking
            candidates.sort(key=lambda x: (-x[1], x[0]))
            best_ix, best_ix_score, best_ix_folds = candidates[0]

            improvement = best_ix_score - best_score

            # Check stopping criterion
            if improvement < IC_IMPROVEMENT_THRESHOLD:
                self._iteration_log.append({
                    "iteration": iteration,
                    "step": "STOP",
                    "reason": (
                        f"Improvement ({improvement:.6f}) < "
                        f"threshold ({IC_IMPROVEMENT_THRESHOLD})"
                    ),
                    "best_candidate": best_ix,
                    "candidate_score": round(best_ix_score, 6),
                    "current_best_score": round(best_score, 6),
                    "improvement": round(improvement, 6),
                    "all_candidate_scores": {
                        c[0]: round(c[1], 6) for c in candidates
                    },
                })
                print(f"\n  ▮ Iteration {iteration}: STOP")
                print(f"    Best candidate: {best_ix} → "
                      f"{best_ix_score:.6f}  (Δ = {improvement:+.6f})")
                print(f"    Improvement below threshold.")
                break

            # Accept the interaction
            selected_interactions.append(best_ix)
            remaining_interactions.remove(best_ix)
            best_score = best_ix_score

            self._iteration_log.append({
                "iteration": iteration,
                "step": "FORWARD",
                "added": best_ix,
                "score_after_add": round(best_ix_score, 6),
                "fold_ics": best_ix_folds,
                "improvement": round(improvement, 6),
                "selected_interactions": list(selected_interactions),
                "total_features": len(base_features) + len(selected_interactions),
                "remaining_candidates": len(remaining_interactions),
                "all_candidate_scores": {
                    c[0]: round(c[1], 6) for c in candidates
                },
            })

            # Decode the interaction for human readability
            parts = best_ix.replace("IX_", "").split("_x_")
            signal_desc = f"{parts[0]} × {parts[1]}" if len(parts) == 2 else best_ix

            print(f"\n  ▶ Iteration {iteration} — FORWARD")
            print(f"    Added: {best_ix}")
            print(f"    Signal: {signal_desc}")
            print(f"    Score: {best_ix_score:.6f}  (Δ = +{improvement:.6f})")
            print(f"    Total features: "
                  f"{len(base_features)} base + "
                  f"{len(selected_interactions)} interactions = "
                  f"{len(base_features) + len(selected_interactions)}")

        total_time = perf_counter() - t0

        # ── Final feature set ───────────────────────────────────────────────
        final_features = base_features + selected_interactions
        final_ic = best_score

        # Compute IC improvement over SFFS baseline
        ic_gain_over_sffs = final_ic - baseline_ic
        ic_gain_pct = (
            (ic_gain_over_sffs / baseline_ic * 100)
            if baseline_ic > 0 else 0.0
        )

        # ── Assemble output ─────────────────────────────────────────────────
        output = {
            "stage": STAGE_NAME,
            "version": VERSION,
            "algorithm": "Forward Selection over Pairwise Interaction Terms",
            "config_snapshot": {
                "ridge_alpha": RIDGE_ALPHA,
                "cv_folds": CV_FOLDS,
                "forward_days": FORWARD_DAYS,
                "max_interactions": MAX_INTERACTIONS,
                "ic_improvement_threshold": IC_IMPROVEMENT_THRESHOLD,
                "base_features_frozen": list(base_features),
                "interaction_candidates_total": len(self._interaction_names),
                "curated_specs_used": len(self._filtered_specs)
                    if self._filtered_specs else 0,
            },
            "sffs_baseline": {
                "features": list(base_features),
                "feature_count": len(base_features),
                "mean_ic_reported": self._base_score,
                "mean_ic_verified": round(baseline_ic, 6),
            },
            "interaction_candidates": [
                {
                    "name": ix,
                    "feature_a": ix.replace("IX_", "").split("_x_")[0],
                    "feature_b": ix.replace("IX_", "").split("_x_")[1]
                        if "_x_" in ix else "?",
                }
                for ix in sorted(self._interaction_names)
            ],
            "selected_interactions": list(selected_interactions),
            "selected_interaction_count": len(selected_interactions),
            "final_feature_set": list(final_features),
            "final_feature_count": len(final_features),
            "final_score_mean_ic": round(final_ic, 6),
            "improvement_over_sffs": {
                "absolute_ic_gain": round(ic_gain_over_sffs, 6),
                "relative_gain_pct": round(ic_gain_pct, 2),
            },
            "iterations": self._iteration_log,
            "runtime_seconds": round(total_time, 2),
        }

        # ── Print summary ───────────────────────────────────────────────────
        print(f"\n  {'═'*60}")
        print(f"  INTERACTION SELECTION RESULT:")
        print(f"  {'═'*60}")
        print(f"  Base features (frozen, from SFFS):")
        for i, feat in enumerate(base_features, 1):
            print(f"    {i}. {feat}")
        if selected_interactions:
            print(f"  Selected interactions:")
            for i, ix in enumerate(selected_interactions, 1):
                parts = ix.replace("IX_", "").split("_x_")
                desc = f"{parts[0]} × {parts[1]}" if len(parts) == 2 else ix
                print(f"    +{i}. {ix}  ({desc})")
        else:
            print(f"  No interactions improved the model.")
        print(f"  ──────────────────────────────────────────────")
        print(f"  SFFS baseline IC  : {baseline_ic:.6f}")
        print(f"  Final IC          : {final_ic:.6f}")
        print(f"  IC gain           : {ic_gain_over_sffs:+.6f} "
              f"({ic_gain_pct:+.2f}%)")
        print(f"  Total features    : {len(final_features)}")
        print(f"  Runtime           : {total_time:.2f}s")
        print(f"  {'═'*60}")

        return output

    # ── 7. Save results atomically ──────────────────────────────────────────
    def save_results(self, results: Dict[str, Any]) -> None:
        """Write interaction_report.json atomically (.tmp → rename).

        Also completes the Auditor lifecycle.
        """
        print(f"\n{'='*72}")
        print(f"[Stage 3] Saving Results")
        print(f"{'='*72}")

        PHASE2_ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)

        # ── Atomic write ────────────────────────────────────────────────────
        tmp_path = OUTPUT_JSON.with_suffix(".json.tmp")
        try:
            with open(tmp_path, "w", encoding="utf-8") as f:
                json.dump(
                    results, f, indent=2, ensure_ascii=False, default=str
                )
            tmp_path.replace(OUTPUT_JSON)
            print(f"  ✓ {OUTPUT_JSON.name} "
                  f"({OUTPUT_JSON.stat().st_size:,} bytes)")
        except Exception as e:
            if tmp_path.exists():
                tmp_path.unlink()
            raise RuntimeError(
                f"[FATAL] Failed to write results: {e}"
            ) from e

        # ── Auditor lifecycle completion ────────────────────────────────────
        try:
            summary_df = pd.DataFrame([{
                "final_feature_count": results["final_feature_count"],
                "final_score_mean_ic": results["final_score_mean_ic"],
                "selected_interaction_count": results["selected_interaction_count"],
                "runtime_seconds": results["runtime_seconds"],
            }])
            self.auditor.record_output(summary_df, self.config.to_snapshot())
            self.auditor.success()
            print(f"  ✓ manifest.json (via Auditor)")
        except Exception as e:
            print(f"  ⚠ Auditor manifest write failed (non-fatal): {e}")

    # ── Orchestrator ────────────────────────────────────────────────────────
    def run(self) -> None:
        """Full pipeline: SFFS → Data → Target → Features → Interactions → Select → Save."""
        pipeline_t0 = perf_counter()

        # Step 1: Load SFFS results → extract base features + baseline IC
        base_features, base_score = self.load_sffs_results()

        # Step 2: Load Phase 1 raw OHLCV
        df = self.load_phase1_data()

        # Step 3: Compute target
        target = self.compute_target(df)
        df["target_log_return"] = target

        # Step 4: Regenerate ONLY the 5 base features (one-time TA cost)
        df = self.regenerate_features(df, base_features)

        # Step 5: Create C(5,2) = 10 interaction columns (instant — column math)
        df, interaction_names = self.create_interaction_columns(df, base_features)

        # Step 6: Forward selection over interactions
        results = self.run_interaction_selection(df)

        # Step 7: Save atomically
        self.save_results(results)

        total_time = perf_counter() - pipeline_t0
        print(f"\n{'='*72}")
        print(f"[Stage 3] COMPLETE — Total runtime: {total_time:.1f}s")
        print(f"{'='*72}\n")


# ─── Main Execution ────────────────────────────────────────────────────────
if __name__ == "__main__":
    print("╔══════════════════════════════════════════════════════════════╗")
    print("║  Phase 2 · Stage 3 — Interaction Term Discovery            ║")
    print(f"║  Version: {VERSION:<49}║")
    print("╚══════════════════════════════════════════════════════════════╝")

    try:
        config = Phase2Config()

        selector = InteractionTermSelector(config=config)
        selector.run()

        sys.exit(0)

    except FileNotFoundError as e:
        print(f"\n[ERROR] {e}", file=sys.stderr)
        sys.exit(1)
    except AssertionError as e:
        print(f"\n[ASSERTION FAILED] {e}", file=sys.stderr)
        sys.exit(2)
    except KeyboardInterrupt:
        print("\n[INTERRUPTED] Interaction selection aborted.", file=sys.stderr)
        sys.exit(130)
    except Exception as e:
        print(f"\n[UNHANDLED ERROR] {type(e).__name__}: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(99)
